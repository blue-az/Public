<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Phoenix | Tau-Bench</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="page">
        <header class="header">
            <span class="badge">Tau-Bench</span>
            <h1>Academic Foundation</h1>
            <p class="subtitle">MIT-licensed research from Sierra Research.</p>
            <a class="back-link" href="index.html">Back to Overview</a>
        </header>

                <nav class="nav">
            <a href="index.html">Home</a>
            <a href="philosophy.html">Philosophy</a>
            <a href="four-phases.html">Four Phases</a>
            <a href="principles.html">Principles</a>
            <a href="tau-bench.html">Tau-Bench</a>
            <a href="domains.html">Domains</a>
            <a href="architecture.html">Architecture</a>
            <a href="PROJECT_PHOENIX_WHITE_PAPER.pdf" target="_blank" rel="noopener">White Paper</a>
        </nav>

        <section class="section">
            <h2>The Problem</h2>
            <p>State-of-the-art function-calling agents still fail a large share of realistic tool-use tasks when measured end-to-end.</p>
            <p>Tau-Bench highlights that reliability and policy adherence are system design problems, not just model-size problems.</p>
            <p><strong>Reference:</strong> <a href="https://taubench.com/#home" target="_blank" rel="noopener">taubench.com/#home</a></p>
        </section>

        <section class="section">
            <h2>Tau-Bench Core Principles</h2>
            <ul>
                <li><strong>SOP-grounded planning:</strong> break complex tasks into explicit, reproducible procedures.</li>
                <li><strong>Policy-first execution:</strong> enforce business or domain rules as explicit constraints.</li>
                <li><strong>Stateful evaluation:</strong> assess multi-turn tool workflows, not isolated prompts.</li>
                <li><strong>Consistency over retries:</strong> track repeatability (pass^k), not one lucky run.</li>
            </ul>
        </section>

        <section class="section">
            <h2>Tau-Bench Challenges -> Phoenix Solutions</h2>
            <table class="table">
                <tr>
                    <th>Tau-Bench Challenge</th>
                    <th>Phoenix Solution</th>
                </tr>
                <tr>
                    <td>Long-context reasoning and planning</td>
                    <td>SOP-driven architecture, Hypothesize -> Plan -> Execute with preview and checkpoints</td>
                </tr>
                <tr>
                    <td>Accurately adhere to complex policies</td>
                    <td><code>rules.py</code> constraints, deterministic tool contracts, and explicit refusal conditions</td>
                </tr>
                <tr>
                    <td>Maintain consistency at scale (pass^k)</td>
                    <td>Write-Then-Verify mandate, golden-file baselines, and regression validation suites</td>
                </tr>
            </table>
        </section>

        <section class="section">
            <h2>Construction Method Alignment</h2>
            <ul>
                <li>Stage I: Manual schema, APIs, and policies -> tools and rules design.</li>
                <li>Stage II: Automatic data generation -> initial database creation.</li>
                <li>Stage III: Manual task annotation -> conversational probing and Q/A sets.</li>
            </ul>
        </section>
    </div>
</body>
</html>
